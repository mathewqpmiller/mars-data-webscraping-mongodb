{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5cae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dependencies\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68967079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Selenium with Chrome\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6586ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the USGS search results page\n",
    "base_url = \"https://astrogeology.usgs.gov\"\n",
    "search_url = f\"{base_url}/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "driver.get(search_url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fd443e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse with BeautifulSoup\n",
    "soup = bs(driver.page_source, 'html.parser')\n",
    "items = soup.find_all('div', class_='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "484738f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Dictionary\n",
    "hemisphere_image_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99fb40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items:\n",
    "    # Extract and clean the title\n",
    "    raw_title = item.find('h3').text.strip()\n",
    "    title = raw_title.replace(\" Enhanced\", \"\").replace(\"Hemisphere\", \"Hemisphere\").strip()\n",
    "\n",
    "    # Build full subpage URL\n",
    "    partial_url = item.find('a')['href']\n",
    "    full_link = base_url + partial_url\n",
    "\n",
    "    # Navigate to subpage\n",
    "    driver.get(full_link)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.LINK_TEXT, 'downloads')))\n",
    "\n",
    "    # Parse subpage\n",
    "    sub_soup = bs(driver.page_source, 'html.parser')\n",
    "    img_url = sub_soup.find('a', text='Sample')['href']\n",
    "\n",
    "    # Append to list\n",
    "    hemisphere_image_urls.append({\n",
    "        'title': title,\n",
    "        'page_url': full_link,\n",
    "        'img_url': img_url\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3f81857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(hemisphere_image_urls, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40036535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 items\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "base_url = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "# Let the page load and parse\n",
    "soup = bs(driver.page_source, 'html.parser')\n",
    "items = soup.find_all('div', class_='item')\n",
    "\n",
    "# Sanity check\n",
    "print(f\"Found {len(items)} items\")\n",
    "\n",
    "for item in items:\n",
    "    try:\n",
    "        # Build the full link to the hemisphere page\n",
    "        partial_url = item.find('a')['href']\n",
    "        full_link = base_url + partial_url\n",
    "\n",
    "        # Go to the hemisphere's detail page\n",
    "        driver.get(full_link)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'h2')))\n",
    "        time.sleep(1)  # Slight delay to ensure page is loaded\n",
    "\n",
    "        # Parse the subpage\n",
    "        sub_soup = bs(driver.page_source, 'html.parser')\n",
    "        title = sub_soup.find('h2', class_='title').text.replace(' Enhanced', '').strip()\n",
    "        img_url = sub_soup.find('a', text='Sample')['href']\n",
    "\n",
    "        # Store in list\n",
    "        hemisphere_image_urls.append({\n",
    "            'title': title,\n",
    "            'img_url': img_url\n",
    "        })\n",
    "        print(f\"Added: {title}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing item: {e}\")\n",
    "\n",
    "# Final check\n",
    "print(hemisphere_image_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb9ad1",
   "metadata": {},
   "source": [
    "# Debugging For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6da6c6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(driver.current_url)\n",
    "print(driver.title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5cd04e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visited main page.\n",
      "Found 0 hemisphere items.\n",
      "\n",
      "Final hemisphere image list:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "def hemisphere_scrape(browser):\n",
    "    # Step 1: Visit the starting page\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(url)\n",
    "    time.sleep(1)\n",
    "    print(\"Visited main page.\")\n",
    "\n",
    "    hemisphere_image_urls = []\n",
    "\n",
    "    # Step 2: Parse the page and find all hemisphere items\n",
    "    html = browser.html\n",
    "    hemi_soup = soup(html, 'html.parser')\n",
    "    items = hemi_soup.find_all('div', class_='item')\n",
    "    print(f\"Found {len(items)} hemisphere items.\")\n",
    "\n",
    "    base_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "    # Step 3: Loop through each item\n",
    "    for index, item in enumerate(items):\n",
    "        print(f\"\\nProcessing hemisphere {index + 1}\")\n",
    "\n",
    "        title = item.find('h3').text\n",
    "        partial_link = item.find('a')['href']\n",
    "        full_link = f\"{base_url}{partial_link}\"\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Link to detail page: {full_link}\")\n",
    "\n",
    "        # Step 4: Visit the hemisphere detail page\n",
    "        browser.visit(full_link)\n",
    "        time.sleep(1)\n",
    "        html = browser.html\n",
    "        img_soup = soup(html, 'html.parser')\n",
    "\n",
    "        # Step 5: Extract the image URL\n",
    "        try:\n",
    "            img_url = img_soup.find('a', text='Sample')['href']\n",
    "            print(f\"Image URL: {img_url}\")\n",
    "        except TypeError:\n",
    "            print(\"Image link not found.\")\n",
    "            img_url = None\n",
    "\n",
    "        # Step 6: Save the result if image is found\n",
    "        if img_url:\n",
    "            hemisphere_image_urls.append({\n",
    "                'title': title,\n",
    "                'img_url': img_url\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Skipping {title} due to missing image.\")\n",
    "\n",
    "        browser.back()\n",
    "\n",
    "    print(\"\\nFinal hemisphere image list:\")\n",
    "    print(hemisphere_image_urls)\n",
    "    return hemisphere_image_urls\n",
    "\n",
    "# Step 0: Set up the browser\n",
    "service = Service(ChromeDriverManager().install())\n",
    "browser = Browser('chrome', service=service, headless=False)\n",
    "\n",
    "# Run the function\n",
    "hemisphere_data = hemisphere_scrape(browser)\n",
    "\n",
    "# Close browser\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc4fdaa",
   "metadata": {},
   "source": [
    "# Debugging Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f22cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.headless = True  # Try running without GUI\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24142d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <meta content=\"light dark\" name=\"color-scheme\"/>\n",
      "  <meta charset=\"utf-8\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <pre>{\"collections\":[{\"abstract\":\"This page introduces the Kaguya Multiband Imager derived spectral and derived mineral maps by the Japan Aerospace Exploration Agency (JAXA) and the University of Hawaii. The mosaics were created from topographically-corrected MI\",\"geoform\":[\"Collection\"],\"name\":\"lunar-kaguya-multiband-imager-mosaics\",\"onlink\":\"https://astrogeology.usgs.gov/search/map/lunar-kaguya-multiband-imager-mosaics\",\"pubdate\":\"2015-01-01\",\"thumb\":\"https://astrogeology.usgs.gov/ckan/dataset/a53c9dbf-e03a-4d7a-8641-fc7af97a75c2/resource/a7e1a610-f8ef-4080-99e0-1b637d6c269f/download/moon-selene-kaguya-mi-thumb.jpg\",\"title\":\"Lunar Kaguya Multiband Imager Mosaics\"},{\"abstract\":\"&lt;span class=\\\"intro\\\"&gt;The following products were the first step of cartography planning&lt;/span&gt; in support of the Cassini-Huygens mission to the Saturian System. Five of Saturans moons are linked below in a standard cartographic\",\"geoform\":[\"Collection\"],\"name\":\"saturn-voyager-airbrush-global-products\",\"onlink\":\"https://astrogeology.usgs.gov/search/map/saturn-voyager-airbrush-global-products\",\"pubdate\":\"2023-10-05\",\"thumb\":\"https://astrogeology.usgs.gov/ckan/dataset/0872355e-41d2-48be-a3f3-474c571911e0/resource/fe0f7b0d-3a95-40f3-ad90-103ee20b2342/download/rhea-voyager-thumb.png\",\"title\":\"Saturn Voyager Airbrush Global Products\"},{\"abstract\":\"&lt;span class=\\\"intro\\\"&gt;Distribute\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "time.sleep(5)\n",
    "soup = bs(driver.page_source, 'html.parser')\n",
    "print(soup.prettify()[:1500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c31490",
   "metadata": {},
   "source": [
    "During the web scraping process, I initially attempted to extract data from the USGS Mars hemispheres webpage using traditional HTML parsing with BeautifulSoup. However, repeated attempts to load the page source resulted in errors, including crashes tied to the Selenium page_source method. Upon closer inspection, I noticed the response was not returning an expected HTML document, but rather a JSON payload embedded within a <pre> tag. This indicated that the endpoint was no longer serving HTML content for direct browser rendering. Instead, it now returns structured data in JSON format, which is meant for programmatic consumption via API calls. This discovery prompted a shift in approachâ€”from HTML scraping to handling and parsing JSON responses using the requests library. This allowed for more efficient and reliable access to the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
